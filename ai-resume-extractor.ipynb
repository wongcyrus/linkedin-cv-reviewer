{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI ChatGPT 3.5 turbo CV Data Extractor\n",
    "Extract CV Reviewer Data and Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from typing import List, Optional\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class StudentCvRecord(BaseModel):\n",
    "    \"\"\"Call this to save a student CV record in markdown format.\"\"\"\n",
    "    name: str = Field(description=\"Name of the student\")\n",
    "    email: Optional[str] = Field(description=\"Email address\")\n",
    "    mobile_number: Optional[str] = Field(description=\"Contact number\")\n",
    "    linkedin_profile_url: str = Field(description=\"LinkedIn profile url\")\n",
    "    resume_rating: int = Field(\n",
    "        description=\"Rating of the resume between 1 to 10\")\n",
    "    rationale: str = Field(description=\"Rationale for the rating\")\n",
    "    warning: str = Field(description=\"Any warning message\")\n",
    "    feedback: str = Field(description=\"Feedback message\")\n",
    "    proposed_job_titles: List[str] = Field(description=\"Proposed job titles\")\n",
    "    certifications: List[str] = Field(description=\"List of certifications\")\n",
    "    technologies: List[str] = Field(description=\"List of technologies\")\n",
    "    skills: List[str] = Field(description=\"List of skills\")\n",
    "    work_experience: List[str] = Field(description=\"List of work experiences\")\n",
    "\n",
    "\n",
    "student_cv_record_function = convert_to_openai_function(StudentCvRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import PydanticOutputFunctionsParser\n",
    "\n",
    "llm35 = AzureChatOpenAI(\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_GPT35_API_VERSION\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_GPT35_DEPLOYMENT_NAME\"),\n",
    "    temperature=0,\n",
    ")\n",
    "model_with_forced_function35 = llm35.bind(\n",
    "    functions=[student_cv_record_function], function_call={\"name\": \"StudentCvRecord\"})\n",
    "\n",
    "cv_path = \"data/TSANG Hin Pak Markus/chatgpt_result.md\"\n",
    "with open(cv_path, \"r\") as f:\n",
    "    cv = f.read()\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a data extraction assistant\"),\n",
    "    (\"user\",\n",
    "     \"{cv}\\nSave a student CV record.\")\n",
    "])\n",
    "\n",
    "parser = PydanticOutputFunctionsParser(pydantic_schema=StudentCvRecord)\n",
    "\n",
    "chain35 = prompt | model_with_forced_function35 | parser\n",
    "\n",
    "llm4o = AzureChatOpenAI(\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_GPT4O_API_VERSION\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_GPT4O_DEPLOYMENT_NAME\"),\n",
    "    temperature=0,\n",
    ")\n",
    "model_with_forced_function4o = llm4o.bind(\n",
    "    functions=[student_cv_record_function], function_call={\"name\": \"StudentCvRecord\"})\n",
    "chain4o = prompt | model_with_forced_function4o | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the path to the \"data\" folder\n",
    "data_folder = \"data\"\n",
    "\n",
    "chatgpt_results = []\n",
    "# Traverse through each subfolder inside the \"data\" folder\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    # Iterate over each file in the current subfolder\n",
    "    for file in files:\n",
    "        if file == \"chatgpt_result.md\":\n",
    "            # Print the file path\n",
    "            chatgpt_results.append(os.path.join(root, file))\n",
    "chatgpt_results.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 8668.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "student_records = []\n",
    "\n",
    "for result_path in tqdm(chatgpt_results):\n",
    "    result_path_json = result_path.replace(\".md\", \".json\")\n",
    "    if os.path.exists(result_path_json):\n",
    "        with open(result_path_json, \"r\") as f:\n",
    "            result_json = f.read()\n",
    "        result = StudentCvRecord.parse_raw(result_json)\n",
    "        student_records.append(result)\n",
    "        continue\n",
    "    with open(result_path, \"r\") as f:\n",
    "        cv = f.read()\n",
    "    name = result_path.split(\"/\")[-2]\n",
    "    try:        \n",
    "        result = chain35.invoke({\"cv\": cv})\n",
    "    except Exception as e:\n",
    "        result = chain4o.invoke({\"cv\": cv})        \n",
    "    \n",
    "    result.name = name\n",
    "   \n",
    "    result_json = json.dumps(result.dict())\n",
    "    with open(result_path_json, \"w\") as f:\n",
    "        f.write(result_json)\n",
    "    student_records.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([record.dict() for record in student_records])\n",
    "df.set_index('name', inplace=True)\n",
    "df.to_excel('data/resumes_reviews.xlsx', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
